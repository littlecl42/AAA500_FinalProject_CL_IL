{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25e411-cbe0-4ca6-8fd6-ee5c2ed9848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# === Step 1: Load and Prepare the Dataset ===\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'Opportunity_Set.xlsx'\n",
    "\n",
    "# Read the Excel file, parse 'Date' as datetime, and set it as the index\n",
    "try:\n",
    "    data = pd.read_excel(file_path, parse_dates=['Date'], index_col='Date')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"The file '{file_path}' was not found.\")\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error parsing the Excel file: {e}\")\n",
    "\n",
    "# Verify that 'Vanguard LifeStrategy Income Fund (VASIX)' exists in the dataset\n",
    "vasix_col = 'Vanguard LifeStrategy Income Fund (VASIX)'\n",
    "if vasix_col not in data.columns:\n",
    "    raise ValueError(f\"Column '{vasix_col}' not found in the dataset.\")\n",
    "\n",
    "# Exclude the benchmark and ensure only numerical asset columns are retained\n",
    "asset_columns = [col for col in data.columns if col not in [vasix_col]]\n",
    "assets = data[asset_columns]\n",
    "\n",
    "# Convert all asset columns to numeric, coercing errors to NaN, and drop rows with any NaN values\n",
    "assets = assets.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Verify that there are enough data points for analysis\n",
    "if assets.shape[0] < 2:\n",
    "    raise ValueError(\"Insufficient data after cleaning. At least two data points are required.\")\n",
    "\n",
    "# === Step 2: Calculate Covariance Matrix ===\n",
    "\n",
    "cov_matrix = assets.cov()\n",
    "\n",
    "# === Step 3: Define Portfolio Optimization Functions ===\n",
    "\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"Calculate the portfolio volatility.\"\"\"\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "def risk_contribution(weights, cov_matrix):\n",
    "    \"\"\"Calculate the risk contribution of each asset to the portfolio.\"\"\"\n",
    "    total_vol = portfolio_volatility(weights, cov_matrix)\n",
    "    marginal_contrib = np.dot(cov_matrix, weights)\n",
    "    return (marginal_contrib * weights) / total_vol\n",
    "\n",
    "def risk_parity_objective(weights, cov_matrix):\n",
    "    \"\"\"Objective function to minimize the standard deviation of risk contributions.\"\"\"\n",
    "    contribs = risk_contribution(weights, cov_matrix)\n",
    "    return np.std(contribs)\n",
    "\n",
    "# === Step 4: Set Up Optimization Constraints and Bounds ===\n",
    "\n",
    "# Constraint: The sum of weights must equal 1\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Bounds: Weights must be between 0 and 1\n",
    "bounds = [(0, 1) for _ in range(len(asset_columns))]\n",
    "\n",
    "# Initial guess: Equally weighted portfolio\n",
    "init_guess = np.ones(len(asset_columns)) / len(asset_columns)\n",
    "\n",
    "# === Step 5: Perform the Optimization ===\n",
    "\n",
    "result = minimize(\n",
    "    fun=risk_parity_objective,\n",
    "    x0=init_guess,\n",
    "    args=(cov_matrix,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# Check if the optimization was successful\n",
    "if not result.success:\n",
    "    raise ValueError(f\"Optimization failed: {result.message}\")\n",
    "\n",
    "# Extract the optimized weights\n",
    "optimal_weights = result.x\n",
    "\n",
    "# === Step 6: Calculate Risk Contributions and Portfolio Standard Deviation ===\n",
    "\n",
    "# Calculate the portfolio's standard deviation\n",
    "portfolio_std = portfolio_volatility(optimal_weights, cov_matrix)\n",
    "\n",
    "# Calculate Risk Contributions\n",
    "risk_contribs = risk_contribution(optimal_weights, cov_matrix)\n",
    "\n",
    "# Create a DataFrame to display weights, risk contributions, and risk contribution percentages\n",
    "risk_contrib_table = pd.DataFrame({\n",
    "    'Asset': asset_columns,\n",
    "    'Weight %': optimal_weights * 100,\n",
    "    'Risk Contribution': risk_contribs,\n",
    "    'Risk Contribution %': risk_contribs / portfolio_std * 100  # Convert to percentage\n",
    "})\n",
    "\n",
    "# Convert the weights to percentages and round to two decimal places\n",
    "risk_contrib_table['Weight %'] = risk_contrib_table['Weight %'].round(2)\n",
    "risk_contrib_table['Risk Contribution %'] = risk_contrib_table['Risk Contribution %'].round(2)\n",
    "\n",
    "# Display the Risk Contribution Table with updated weights and contributions\n",
    "print(f\"Portfolio Standard Deviation (monthly): {portfolio_std:.6f}\\n\")\n",
    "print(\"Risk Contribution to Portfolio Standard Deviation:\")\n",
    "print(risk_contrib_table.to_string(index=False))\n",
    "\n",
    "# === Step 7: Calculate Portfolio and Benchmark Returns ===\n",
    "\n",
    "# Calculate portfolio returns using the optimized weights\n",
    "portfolio_returns = assets.dot(optimal_weights)\n",
    "\n",
    "# Extract benchmark returns\n",
    "benchmark_returns = data[vasix_col].loc[portfolio_returns.index]\n",
    "\n",
    "# Combine portfolio and benchmark returns into a single DataFrame\n",
    "performance_df = pd.DataFrame({\n",
    "    'Risk Parity Portfolio': portfolio_returns,\n",
    "    'VASIX (Benchmark)': benchmark_returns\n",
    "}).dropna()\n",
    "\n",
    "# Ensure the index is datetime and sorted\n",
    "performance_df.index = pd.to_datetime(performance_df.index)\n",
    "performance_df = performance_df.sort_index()\n",
    "\n",
    "# === Step 8: Define Performance Metrics Functions ===\n",
    "\n",
    "def calculate_cagr(df, column_name):\n",
    "    \"\"\"Calculate the Compound Annual Growth Rate (CAGR).\"\"\"\n",
    "    if df.index.nunique() < 2:\n",
    "        raise ValueError(f\"Date range is too short to calculate CAGR for {column_name}.\")\n",
    "    \n",
    "    # Calculate the number of years between the first and last date\n",
    "    days_diff = (df.index[-1] - df.index[0]).days\n",
    "    if days_diff <= 0:\n",
    "        raise ValueError(\"Date range is too short to calculate CAGR.\")\n",
    "    \n",
    "    years = days_diff / 365.25\n",
    "    cumulative_return = (1 + df[column_name]).prod()\n",
    "    \n",
    "    return (cumulative_return ** (1 / years) - 1) * 100  # Convert to percentage\n",
    "\n",
    "def calculate_max_drawdown(df, column_name):\n",
    "    \"\"\"Calculate the Maximum Drawdown.\"\"\"\n",
    "    cumulative_return = (1 + df[column_name]).cumprod()\n",
    "    rolling_max = cumulative_return.cummax()\n",
    "    drawdown = (cumulative_return - rolling_max) / rolling_max\n",
    "    return drawdown.min() * 100  # Convert to percentage\n",
    "\n",
    "# === Step 9: Calculate Annual Returns ===\n",
    "\n",
    "def calculate_annual_returns(df, column_name):\n",
    "    \"\"\"Calculate annual returns for the portfolio.\"\"\"\n",
    "    # Resample data to year-end using 'YE' for year-end\n",
    "    annual_returns = df[column_name].resample('YE').apply(lambda x: (1 + x).prod() - 1)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    return (annual_returns * 100).round(2)\n",
    "\n",
    "# Calculate annual returns for both portfolio and benchmark\n",
    "annual_returns_portfolio = calculate_annual_returns(performance_df, 'Risk Parity Portfolio')\n",
    "annual_returns_benchmark = calculate_annual_returns(performance_df, 'VASIX (Benchmark)')\n",
    "\n",
    "# Combine annual returns into a DataFrame\n",
    "annual_returns_table = pd.DataFrame({\n",
    "    'Risk Parity Portfolio (%)': annual_returns_portfolio,\n",
    "    'VASIX (Benchmark) (%)': annual_returns_benchmark\n",
    "})\n",
    "\n",
    "# Display the annual return table\n",
    "print(\"\\nAnnual Return Table:\")\n",
    "print(annual_returns_table.to_string())\n",
    "\n",
    "\n",
    "# === Step 10: Calculate Performance Metrics ===\n",
    "\n",
    "if performance_df.index.nunique() < 2:\n",
    "    print(\"Date range is too short for CAGR calculation. Skipping CAGR.\")\n",
    "else:\n",
    "    try:\n",
    "        # Calculate CAGR for both portfolio and benchmark\n",
    "        cagr_portfolio = calculate_cagr(performance_df, 'Risk Parity Portfolio')\n",
    "        cagr_benchmark = calculate_cagr(performance_df, 'VASIX (Benchmark)')\n",
    "        \n",
    "        # Calculate Standard Deviation (annualized and converted to percentage)\n",
    "        std_portfolio = portfolio_returns.std() * np.sqrt(12) * 100  # Assuming monthly returns\n",
    "        std_benchmark = benchmark_returns.std() * np.sqrt(12) * 100\n",
    "        \n",
    "        # Calculate Maximum Drawdown for both portfolio and benchmark\n",
    "        mdd_portfolio = calculate_max_drawdown(performance_df, 'Risk Parity Portfolio')\n",
    "        mdd_benchmark = calculate_max_drawdown(performance_df, 'VASIX (Benchmark)')\n",
    "        \n",
    "        # Compile the performance metrics into a DataFrame\n",
    "        performance_metrics = pd.DataFrame({\n",
    "            'CAGR (%)': [cagr_portfolio, cagr_benchmark],\n",
    "            'Standard Deviation (%)': [std_portfolio, std_benchmark],\n",
    "            'Maximum Drawdown (%)': [mdd_portfolio, mdd_benchmark]\n",
    "        }, index=['Risk Parity Portfolio', 'VASIX (Benchmark)'])\n",
    "        \n",
    "        # Format and display the Performance Metrics with two decimal places\n",
    "        print(\"\\nPerformance Metrics (in percentages):\")\n",
    "        print(performance_metrics.round(2).to_string())\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating performance metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5c5be-0c6f-473e-8b37-09f942eed862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# === Step 1: Load and Prepare the Dataset ===\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'Opportunity_Set.xlsx'\n",
    "\n",
    "# Read the Excel file, parse 'Date' as datetime, and set it as the index\n",
    "try:\n",
    "    data = pd.read_excel(file_path, parse_dates=['Date'], index_col='Date')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"The file '{file_path}' was not found.\")\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error parsing the Excel file: {e}\")\n",
    "\n",
    "# Verify that 'Vanguard LifeStrategy Income Fund (VASIX)' exists in the dataset\n",
    "vasix_col = 'Vanguard LifeStrategy Income Fund (VASIX)'\n",
    "if vasix_col not in data.columns:\n",
    "    raise ValueError(f\"Column '{vasix_col}' not found in the dataset.\")\n",
    "\n",
    "# Exclude the benchmark and ensure only numerical asset columns are retained\n",
    "asset_columns = [col for col in data.columns if col not in [vasix_col]]\n",
    "assets = data[asset_columns]\n",
    "\n",
    "# Convert all asset columns to numeric, coercing errors to NaN, and drop rows with any NaN values\n",
    "assets = assets.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Verify that there are enough data points for analysis\n",
    "if assets.shape[0] < 2:\n",
    "    raise ValueError(\"Insufficient data after cleaning. At least two data points are required.\")\n",
    "\n",
    "# === Step 2: Calculate Covariance Matrix ===\n",
    "\n",
    "cov_matrix = assets.cov()\n",
    "\n",
    "# === Step 3: Define Portfolio Optimization Functions ===\n",
    "\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"Calculate the portfolio volatility.\"\"\"\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "def risk_contribution(weights, cov_matrix):\n",
    "    \"\"\"Calculate the risk contribution of each asset to the portfolio.\"\"\"\n",
    "    total_vol = portfolio_volatility(weights, cov_matrix)\n",
    "    marginal_contrib = np.dot(cov_matrix, weights)\n",
    "    return (marginal_contrib * weights) / total_vol\n",
    "\n",
    "# === Step 4: Minimum Variance Portfolio Objective Function ===\n",
    "\n",
    "def min_variance_objective(weights, cov_matrix):\n",
    "    \"\"\"Objective function to minimize portfolio variance.\"\"\"\n",
    "    return portfolio_volatility(weights, cov_matrix)\n",
    "\n",
    "# === Step 5: Set Up Optimization Constraints and Bounds ===\n",
    "\n",
    "# Constraint: The sum of weights must equal 1\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Bounds: Weights must be between 0 and 1 (long-only constraint)\n",
    "bounds = [(0, 1) for _ in range(len(asset_columns))]\n",
    "\n",
    "# Initial guess: Equally weighted portfolio\n",
    "init_guess = np.ones(len(asset_columns)) / len(asset_columns)\n",
    "\n",
    "# === Step 6: Perform the Optimization for Minimum Variance Portfolio ===\n",
    "\n",
    "result = minimize(\n",
    "    fun=min_variance_objective,\n",
    "    x0=init_guess,\n",
    "    args=(cov_matrix,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# Check if the optimization was successful\n",
    "if not result.success:\n",
    "    raise ValueError(f\"Optimization failed: {result.message}\")\n",
    "\n",
    "# Extract the optimized weights for the minimum variance portfolio\n",
    "optimal_weights = result.x\n",
    "\n",
    "# === Step 7: Calculate Risk Contributions and Portfolio Standard Deviation ===\n",
    "\n",
    "# Calculate the portfolio's standard deviation\n",
    "portfolio_std = portfolio_volatility(optimal_weights, cov_matrix)\n",
    "\n",
    "# Calculate Risk Contributions\n",
    "risk_contribs = risk_contribution(optimal_weights, cov_matrix)\n",
    "\n",
    "# Create a DataFrame to display weights, risk contributions, and risk contribution percentages\n",
    "risk_contrib_table = pd.DataFrame({\n",
    "    'Asset': asset_columns,\n",
    "    'Weight %': optimal_weights * 100,\n",
    "    'Risk Contribution': risk_contribs,\n",
    "    'Risk Contribution %': risk_contribs / portfolio_std * 100  # Convert to percentage\n",
    "})\n",
    "\n",
    "# Convert the weights to percentages and round to two decimal places\n",
    "risk_contrib_table['Weight %'] = risk_contrib_table['Weight %'].round(2)\n",
    "risk_contrib_table['Risk Contribution %'] = risk_contrib_table['Risk Contribution %'].round(2)\n",
    "\n",
    "# Display the Risk Contribution Table with updated weights and contributions\n",
    "print(f\"Portfolio Standard Deviation (monthly): {portfolio_std:.6f}\\n\")\n",
    "print(\"Risk Contribution to Portfolio Standard Deviation:\")\n",
    "print(risk_contrib_table.to_string(index=False))\n",
    "\n",
    "# === Step 8: Calculate Portfolio Returns ===\n",
    "\n",
    "# Calculate portfolio returns using the optimized weights\n",
    "portfolio_returns = assets.dot(optimal_weights)\n",
    "\n",
    "# Extract benchmark returns\n",
    "benchmark_returns = data[vasix_col].loc[portfolio_returns.index]\n",
    "\n",
    "# Combine portfolio and benchmark returns into a single DataFrame\n",
    "performance_df = pd.DataFrame({\n",
    "    'Minimum Variance Portfolio': portfolio_returns,\n",
    "    'VASIX (Benchmark)': benchmark_returns\n",
    "}).dropna()\n",
    "\n",
    "# Ensure the index is datetime and sorted\n",
    "performance_df.index = pd.to_datetime(performance_df.index)\n",
    "performance_df = performance_df.sort_index()\n",
    "\n",
    "# === Step 9: Define Performance Metrics Functions ===\n",
    "\n",
    "def calculate_cagr(df, column_name):\n",
    "    \"\"\"Calculate the Compound Annual Growth Rate (CAGR).\"\"\"\n",
    "    if df.index.nunique() < 2:\n",
    "        raise ValueError(f\"Date range is too short to calculate CAGR for {column_name}.\")\n",
    "    \n",
    "    # Calculate the number of years between the first and last date\n",
    "    days_diff = (df.index[-1] - df.index[0]).days\n",
    "    if days_diff <= 0:\n",
    "        raise ValueError(\"Date range is too short to calculate CAGR.\")\n",
    "    \n",
    "    years = days_diff / 365.25\n",
    "    cumulative_return = (1 + df[column_name]).prod()\n",
    "    \n",
    "    return (cumulative_return ** (1 / years) - 1) * 100  # Convert to percentage\n",
    "\n",
    "def calculate_max_drawdown(df, column_name):\n",
    "    \"\"\"Calculate the Maximum Drawdown.\"\"\"\n",
    "    cumulative_return = (1 + df[column_name]).cumprod()\n",
    "    rolling_max = cumulative_return.cummax()\n",
    "    drawdown = (cumulative_return - rolling_max) / rolling_max\n",
    "    return drawdown.min() * 100  # Convert to percentage\n",
    "\n",
    "# === Step 10: Calculate Annual Returns ===\n",
    "\n",
    "def calculate_annual_returns(df, column_name):\n",
    "    \"\"\"Calculate annual returns for the portfolio.\"\"\"\n",
    "    # Resample data to year-end using 'YE' for year-end\n",
    "    annual_returns = df[column_name].resample('YE').apply(lambda x: (1 + x).prod() - 1)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    return (annual_returns * 100).round(2)\n",
    "\n",
    "# Calculate annual returns for both portfolio and benchmark\n",
    "annual_returns_portfolio = calculate_annual_returns(performance_df, 'Minimum Variance Portfolio')\n",
    "annual_returns_benchmark = calculate_annual_returns(performance_df, 'VASIX (Benchmark)')\n",
    "\n",
    "# Combine annual returns into a DataFrame\n",
    "annual_returns_table = pd.DataFrame({\n",
    "    'Minimum Variance Portfolio (%)': annual_returns_portfolio,\n",
    "    'VASIX (Benchmark) (%)': annual_returns_benchmark\n",
    "})\n",
    "\n",
    "# Display the annual return table\n",
    "print(\"\\nAnnual Return Table:\")\n",
    "print(annual_returns_table.to_string())\n",
    "\n",
    "# === Step 11: Calculate Performance Metrics ===\n",
    "\n",
    "if performance_df.index.nunique() < 2:\n",
    "    print(\"Date range is too short for CAGR calculation. Skipping CAGR.\")\n",
    "else:\n",
    "    try:\n",
    "        # Calculate CAGR for both portfolio and benchmark\n",
    "        cagr_portfolio = calculate_cagr(performance_df, 'Minimum Variance Portfolio')\n",
    "        cagr_benchmark = calculate_cagr(performance_df, 'VASIX (Benchmark)')\n",
    "        \n",
    "        # Calculate Standard Deviation (annualized and converted to percentage)\n",
    "        std_portfolio = portfolio_returns.std() * np.sqrt(12) * 100  # Assuming monthly returns\n",
    "        std_benchmark = benchmark_returns.std() * np.sqrt(12) * 100\n",
    "        \n",
    "        # Calculate Maximum Drawdown for both portfolio and benchmark\n",
    "        mdd_portfolio = calculate_max_drawdown(performance_df, 'Minimum Variance Portfolio')\n",
    "        mdd_benchmark = calculate_max_drawdown(performance_df, 'VASIX (Benchmark)')\n",
    "        \n",
    "        # Compile the performance metrics into a DataFrame\n",
    "        performance_metrics = pd.DataFrame({\n",
    "            'CAGR (%)': [cagr_portfolio, cagr_benchmark],\n",
    "            'Standard Deviation (%)': [std_portfolio, std_benchmark],\n",
    "            'Maximum Drawdown (%)': [mdd_portfolio, mdd_benchmark]\n",
    "        }, index=['Minimum Variance Portfolio', 'VASIX (Benchmark)'])\n",
    "        \n",
    "        # Format and display the Performance Metrics with two decimal places\n",
    "        print(\"\\nPerformance Metrics (in percentages):\")\n",
    "        print(performance_metrics.round(2).to_string())\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating performance metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09def82b-4adb-4a2d-ae9c-2cb0b685ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# === Step 1: Load and Prepare the Dataset ===\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'Opportunity_Set.xlsx'\n",
    "\n",
    "# Read the Excel file, parse 'Date' as datetime, and set it as the index\n",
    "try:\n",
    "    data = pd.read_excel(file_path, parse_dates=['Date'], index_col='Date')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"The file '{file_path}' was not found.\")\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error parsing the Excel file: {e}\")\n",
    "\n",
    "# Verify that 'Vanguard LifeStrategy Income Fund (VASIX)' exists in the dataset\n",
    "vasix_col = 'Vanguard LifeStrategy Income Fund (VASIX)'\n",
    "if vasix_col not in data.columns:\n",
    "    raise ValueError(f\"Column '{vasix_col}' not found in the dataset.\")\n",
    "\n",
    "# Exclude the benchmark and ensure only numerical asset columns are retained\n",
    "asset_columns = [col for col in data.columns if col not in [vasix_col]]\n",
    "assets = data[asset_columns]\n",
    "\n",
    "# Convert all asset columns to numeric, coercing errors to NaN, and drop rows with any NaN values\n",
    "assets = assets.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Verify that there are enough data points for analysis\n",
    "if assets.shape[0] < 2:\n",
    "    raise ValueError(\"Insufficient data after cleaning. At least two data points are required.\")\n",
    "\n",
    "# === Step 2: Calculate Covariance Matrix and Standard Deviations ===\n",
    "\n",
    "cov_matrix = assets.cov()\n",
    "asset_std = assets.std()  # Standard deviation (volatility) of individual assets\n",
    "\n",
    "# === Step 3: Define Maximum Diversification Objective Function ===\n",
    "\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"Calculate the portfolio volatility.\"\"\"\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "def diversification_ratio(weights, asset_std, cov_matrix):\n",
    "    \"\"\"Calculate the Diversification Ratio.\"\"\"\n",
    "    weighted_volatility_sum = np.dot(weights, asset_std)  # Sum of weighted asset volatilities\n",
    "    portfolio_vol = portfolio_volatility(weights, cov_matrix)  # Portfolio volatility\n",
    "    return weighted_volatility_sum / portfolio_vol\n",
    "\n",
    "def max_diversification_objective(weights, asset_std, cov_matrix):\n",
    "    \"\"\"Objective function to maximize the diversification ratio.\"\"\"\n",
    "    return -diversification_ratio(weights, asset_std, cov_matrix)  # Minimize the negative of DR\n",
    "\n",
    "# === Step 4: Set Up Optimization Constraints and Bounds ===\n",
    "\n",
    "# Constraint: The sum of weights must equal 1\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Bounds: Weights must be between 0 and 1 (long-only constraint)\n",
    "bounds = [(0, 1) for _ in range(len(asset_columns))]\n",
    "\n",
    "# Initial guess: Equally weighted portfolio\n",
    "init_guess = np.ones(len(asset_columns)) / len(asset_columns)\n",
    "\n",
    "# === Step 5: Perform the Optimization for Maximum Diversification Portfolio ===\n",
    "\n",
    "result = minimize(\n",
    "    fun=max_diversification_objective,\n",
    "    x0=init_guess,\n",
    "    args=(asset_std, cov_matrix),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# Check if the optimization was successful\n",
    "if not result.success:\n",
    "    raise ValueError(f\"Optimization failed: {result.message}\")\n",
    "\n",
    "# Extract the optimized weights for the maximum diversification portfolio\n",
    "optimal_weights = result.x\n",
    "\n",
    "# === Step 6: Calculate Portfolio Volatility and Diversification Ratio ===\n",
    "\n",
    "portfolio_std = portfolio_volatility(optimal_weights, cov_matrix)\n",
    "div_ratio = diversification_ratio(optimal_weights, asset_std, cov_matrix)\n",
    "\n",
    "# === Step 7: Calculate Risk Contributions ===\n",
    "\n",
    "risk_contribs = risk_contribution(optimal_weights, cov_matrix)\n",
    "\n",
    "# Create a DataFrame to display weights, risk contributions, and risk contribution percentages\n",
    "risk_contrib_table = pd.DataFrame({\n",
    "    'Asset': asset_columns,\n",
    "    'Weight %': optimal_weights * 100,\n",
    "    'Risk Contribution': risk_contribs,\n",
    "    'Risk Contribution %': risk_contribs / portfolio_std * 100  # Convert to percentage\n",
    "})\n",
    "\n",
    "# Convert the weights to percentages and round to two decimal places\n",
    "risk_contrib_table['Weight %'] = risk_contrib_table['Weight %'].round(2)\n",
    "risk_contrib_table['Risk Contribution %'] = risk_contrib_table['Risk Contribution %'].round(2)\n",
    "\n",
    "# Display the Risk Contribution Table with updated weights and contributions\n",
    "print(f\"Portfolio Standard Deviation (monthly): {portfolio_std:.6f}\")\n",
    "print(f\"Diversification Ratio: {div_ratio:.4f}\\n\")\n",
    "print(\"Risk Contribution to Portfolio Standard Deviation:\")\n",
    "print(risk_contrib_table.to_string(index=False))\n",
    "\n",
    "# === Step 8: Calculate Portfolio Returns ===\n",
    "\n",
    "# Calculate portfolio returns using the optimized weights\n",
    "portfolio_returns = assets.dot(optimal_weights)\n",
    "\n",
    "# Extract benchmark returns\n",
    "benchmark_returns = data[vasix_col].loc[portfolio_returns.index]\n",
    "\n",
    "# Combine portfolio and benchmark returns into a single DataFrame\n",
    "performance_df = pd.DataFrame({\n",
    "    'Maximum Diversification Portfolio': portfolio_returns,\n",
    "    'VASIX (Benchmark)': benchmark_returns\n",
    "}).dropna()\n",
    "\n",
    "# Ensure the index is datetime and sorted\n",
    "performance_df.index = pd.to_datetime(performance_df.index)\n",
    "performance_df = performance_df.sort_index()\n",
    "\n",
    "# === Step 9: Define Performance Metrics Functions ===\n",
    "\n",
    "def calculate_cagr(df, column_name):\n",
    "    \"\"\"Calculate the Compound Annual Growth Rate (CAGR).\"\"\"\n",
    "    if df.index.nunique() < 2:\n",
    "        raise ValueError(f\"Date range is too short to calculate CAGR for {column_name}.\")\n",
    "    \n",
    "    # Calculate the number of years between the first and last date\n",
    "    days_diff = (df.index[-1] - df.index[0]).days\n",
    "    if days_diff <= 0:\n",
    "        raise ValueError(\"Date range is too short to calculate CAGR.\")\n",
    "    \n",
    "    years = days_diff / 365.25\n",
    "    cumulative_return = (1 + df[column_name]).prod()\n",
    "    \n",
    "    return (cumulative_return ** (1 / years) - 1) * 100  # Convert to percentage\n",
    "\n",
    "def calculate_max_drawdown(df, column_name):\n",
    "    \"\"\"Calculate the Maximum Drawdown.\"\"\"\n",
    "    cumulative_return = (1 + df[column_name]).cumprod()\n",
    "    rolling_max = cumulative_return.cummax()\n",
    "    drawdown = (cumulative_return - rolling_max) / rolling_max\n",
    "    return drawdown.min() * 100  # Convert to percentage\n",
    "\n",
    "# === Step 10: Calculate Annual Returns ===\n",
    "\n",
    "def calculate_annual_returns(df, column_name):\n",
    "    \"\"\"Calculate annual returns for the portfolio.\"\"\"\n",
    "    # Resample data to year-end using 'YE' for year-end\n",
    "    annual_returns = df[column_name].resample('YE').apply(lambda x: (1 + x).prod() - 1)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    return (annual_returns * 100).round(2)\n",
    "\n",
    "# Calculate annual returns for both portfolio and benchmark\n",
    "annual_returns_portfolio = calculate_annual_returns(performance_df, 'Maximum Diversification Portfolio')\n",
    "annual_returns_benchmark = calculate_annual_returns(performance_df, 'VASIX (Benchmark)')\n",
    "\n",
    "# Combine annual returns into a DataFrame\n",
    "annual_returns_table = pd.DataFrame({\n",
    "    'Maximum Diversification Portfolio (%)': annual_returns_portfolio,\n",
    "    'VASIX (Benchmark) (%)': annual_returns_benchmark\n",
    "})\n",
    "\n",
    "# Display the annual return table\n",
    "print(\"\\nAnnual Return Table:\")\n",
    "print(annual_returns_table.to_string())\n",
    "\n",
    "# === Step 11: Calculate Performance Metrics ===\n",
    "\n",
    "if performance_df.index.nunique() < 2:\n",
    "    print(\"Date range is too short for CAGR calculation. Skipping CAGR.\")\n",
    "else:\n",
    "    try:\n",
    "        # Calculate CAGR for both portfolio and benchmark\n",
    "        cagr_portfolio = calculate_cagr(performance_df, 'Maximum Diversification Portfolio')\n",
    "        cagr_benchmark = calculate_cagr(performance_df, 'VASIX (Benchmark)')\n",
    "        \n",
    "        # Calculate Standard Deviation (annualized and converted to percentage)\n",
    "        std_portfolio = portfolio_returns.std() * np.sqrt(12) * 100  # Assuming monthly returns\n",
    "        std_benchmark = benchmark_returns.std() * np.sqrt(12) * 100\n",
    "        \n",
    "        # Calculate Maximum Drawdown for both portfolio and benchmark\n",
    "        mdd_portfolio = calculate_max_drawdown(performance_df, 'Maximum Diversification Portfolio')\n",
    "        mdd_benchmark = calculate_max_drawdown(performance_df, 'VASIX (Benchmark)')\n",
    "        \n",
    "        # Compile the performance metrics into a DataFrame\n",
    "        performance_metrics = pd.DataFrame({\n",
    "            'CAGR (%)': [cagr_portfolio, cagr_benchmark],\n",
    "            'Standard Deviation (%)': [std_portfolio, std_benchmark],\n",
    "            'Maximum Drawdown (%)': [mdd_portfolio, mdd_benchmark]\n",
    "        }, index=['Maximum Diversification Portfolio', 'VASIX (Benchmark)'])\n",
    "\n",
    "        # Format and display the Performance Metrics with two decimal places\n",
    "        print(\"\\nPerformance Metrics (in percentages):\")\n",
    "        print(performance_metrics.round(2).to_string())\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating performance metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b76dd70-9f02-43b8-8884-f055b092d4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Weights Table (%):\n",
      "                                           Asset  Risk Parity  Min Variance  Max Diversification\n",
      "             Vanguard Total World Stock ETF (VT)        11.62         15.84                23.15\n",
      "    PIMCO 25+ Year Zero Coupon US Trs ETF (ZROZ)         4.75          2.01                 3.38\n",
      "             AQR Diversified Arbitrage I (ADAIX)        15.04         22.46                 8.49\n",
      "                        iShares Gold Trust (IAU)         4.05          3.29                 0.00\n",
      "                 Bitcoin Market Price USD (^BTC)         0.92          0.00                 0.46\n",
      "AQR Risk-Balanced Commodities Strategy I (ARCIX)         4.27          0.31                 4.08\n",
      "                 AQR Long-Short Equity I (QLEIX)         4.58          0.00                 0.00\n",
      "          AQR Style Premia Alternative I (QSPIX)         3.82          0.00                 0.00\n",
      "             AQR Equity Market Neutral I (QMNIX)         5.59          9.09                 9.16\n",
      "               AQR Macro Opportunities I (QGMIX)         8.89          7.80                 8.07\n",
      "        AGF U.S. Market Neutral Anti-Beta (BTAL)         6.13          6.69                 8.73\n",
      "       AQR Managed Futures Strategy HV I (QMHIX)         2.68          0.00                 0.00\n",
      "              Invesco DB US Dollar Bullish (UUP)        22.30         27.87                26.54\n",
      "           ProShares VIX Mid-Term Futures (VIXM)         5.36          4.64                 7.92\n",
      "\n",
      "Risk Contribution Table (%):\n",
      "                                           Asset  Risk Parity  Min Variance  Max Diversification\n",
      "             Vanguard Total World Stock ETF (VT)         7.19         16.90                27.12\n",
      "    PIMCO 25+ Year Zero Coupon US Trs ETF (ZROZ)         7.11          1.94                 5.54\n",
      "             AQR Diversified Arbitrage I (ADAIX)         7.09         22.05                 3.87\n",
      "                        iShares Gold Trust (IAU)         7.14          3.30                 0.00\n",
      "                 Bitcoin Market Price USD (^BTC)         7.10          0.00                 2.74\n",
      "AQR Risk-Balanced Commodities Strategy I (ARCIX)         7.18          0.29                 5.16\n",
      "                 AQR Long-Short Equity I (QLEIX)         7.15          0.00                 0.00\n",
      "          AQR Style Premia Alternative I (QSPIX)         7.16          0.00                 0.00\n",
      "             AQR Equity Market Neutral I (QMNIX)         7.14          9.25                 7.09\n",
      "               AQR Macro Opportunities I (QGMIX)         7.16          7.90                 4.74\n",
      "        AGF U.S. Market Neutral Anti-Beta (BTAL)         7.11          6.49                10.08\n",
      "       AQR Managed Futures Strategy HV I (QMHIX)         7.17          0.00                 0.00\n",
      "              Invesco DB US Dollar Bullish (UUP)         7.16         27.48                13.68\n",
      "           ProShares VIX Mid-Term Futures (VIXM)         7.14          4.40                19.98\n",
      "\n",
      "Annual Return Table (%):\n",
      "            Risk Parity (%)  Minimum Variance (%)  Maximum Diversification (%)  VASIX (Benchmark) (%)\n",
      "Date                                                                                                 \n",
      "2014-12-31             2.11                  1.77                         1.77                   0.89\n",
      "2015-12-31             1.36                  1.39                         1.29                   0.23\n",
      "2016-12-31             4.17                  3.82                         3.35                   4.60\n",
      "2017-12-31             3.51                 -0.03                         0.39                   6.97\n",
      "2018-12-31            -0.34                  2.60                         1.60                  -1.06\n",
      "2019-12-31             7.19                  6.64                         7.48                  12.05\n",
      "2020-12-31             9.11                  8.56                         9.61                   9.14\n",
      "2021-12-31             7.99                  5.97                         7.47                   1.92\n",
      "2022-12-31             5.71                  4.01                         3.29                 -13.93\n",
      "2023-12-31             4.62                  4.07                         3.03                   9.48\n",
      "2024-12-31             7.27                  6.92                         6.94                   5.21\n",
      "\n",
      "Performance Metrics Table:\n",
      "                        Risk Parity  Minimum Variance  Maximum Diversification  VASIX (Benchmark)\n",
      "CAGR (%)                       5.38              4.66                     4.71               3.38\n",
      "Standard Deviation (%)         2.93              2.35                     2.61               5.63\n",
      "Maximum Drawdown (%)          -2.87             -2.21                    -2.77             -16.72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# === Helper Functions ===\n",
    "\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"Calculate the portfolio volatility.\"\"\"\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "def risk_contribution(weights, cov_matrix):\n",
    "    \"\"\"Calculate the risk contribution of each asset to the portfolio.\"\"\"\n",
    "    total_vol = portfolio_volatility(weights, cov_matrix)\n",
    "    marginal_contrib = np.dot(cov_matrix, weights)\n",
    "    return (marginal_contrib * weights) / total_vol\n",
    "\n",
    "def calculate_cagr(df, column_name):\n",
    "    \"\"\"Calculate the Compound Annual Growth Rate (CAGR).\"\"\"\n",
    "    days_diff = (df.index[-1] - df.index[0]).days\n",
    "    years = days_diff / 365.25\n",
    "    cumulative_return = (1 + df[column_name]).prod()\n",
    "    return (cumulative_return ** (1 / years) - 1) * 100  # Convert to percentage\n",
    "\n",
    "def calculate_max_drawdown(df, column_name):\n",
    "    \"\"\"Calculate the Maximum Drawdown.\"\"\"\n",
    "    cumulative_return = (1 + df[column_name]).cumprod()\n",
    "    rolling_max = cumulative_return.cummax()\n",
    "    drawdown = (cumulative_return - rolling_max) / rolling_max\n",
    "    return drawdown.min() * 100  # Convert to percentage\n",
    "\n",
    "def calculate_annual_returns(df, column_name):\n",
    "    \"\"\"Calculate annual returns for the portfolio.\"\"\"\n",
    "    annual_returns = df[column_name].resample('YE').apply(lambda x: (1 + x).prod() - 1)\n",
    "    return (annual_returns * 100).round(2)  # Convert to percentage and round\n",
    "\n",
    "# === Portfolio Optimizations ===\n",
    "\n",
    "def optimize_risk_parity(cov_matrix):\n",
    "    def risk_parity_objective(weights, cov_matrix):\n",
    "        contribs = risk_contribution(weights, cov_matrix)\n",
    "        return np.std(contribs)\n",
    "\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "    bounds = [(0, 1) for _ in range(len(cov_matrix))]\n",
    "    init_guess = np.ones(len(cov_matrix)) / len(cov_matrix)\n",
    "\n",
    "    result = minimize(risk_parity_objective, init_guess, args=(cov_matrix,), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "def optimize_min_variance(cov_matrix):\n",
    "    def min_variance_objective(weights, cov_matrix):\n",
    "        return portfolio_volatility(weights, cov_matrix)\n",
    "\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "    bounds = [(0, 1) for _ in range(len(cov_matrix))]\n",
    "    init_guess = np.ones(len(cov_matrix)) / len(cov_matrix)\n",
    "\n",
    "    result = minimize(min_variance_objective, init_guess, args=(cov_matrix,), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "def optimize_max_diversification(cov_matrix, asset_std):\n",
    "    def diversification_ratio(weights, asset_std, cov_matrix):\n",
    "        weighted_volatility_sum = np.dot(weights, asset_std)\n",
    "        portfolio_vol = portfolio_volatility(weights, cov_matrix)\n",
    "        return weighted_volatility_sum / portfolio_vol\n",
    "\n",
    "    def max_diversification_objective(weights, asset_std, cov_matrix):\n",
    "        return -diversification_ratio(weights, asset_std, cov_matrix)\n",
    "\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "    bounds = [(0, 1) for _ in range(len(cov_matrix))]\n",
    "    init_guess = np.ones(len(cov_matrix)) / len(cov_matrix)\n",
    "\n",
    "    result = minimize(max_diversification_objective, init_guess, args=(asset_std, cov_matrix), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "# === Load Data ===\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'Opportunity_Set.xlsx'\n",
    "\n",
    "# Read the Excel file, parse 'Date' as datetime, and set it as the index\n",
    "data = pd.read_excel(file_path, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Exclude the benchmark and keep only asset columns\n",
    "asset_columns = [col for col in data.columns if col != 'Vanguard LifeStrategy Income Fund (VASIX)']\n",
    "assets = data[asset_columns].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Calculate the covariance matrix and asset volatilities (std)\n",
    "cov_matrix = assets.cov()\n",
    "asset_std = assets.std()\n",
    "\n",
    "# === Perform Optimizations for all Portfolios ===\n",
    "\n",
    "weights_risk_parity = optimize_risk_parity(cov_matrix)\n",
    "weights_min_variance = optimize_min_variance(cov_matrix)\n",
    "weights_max_diversification = optimize_max_diversification(cov_matrix, asset_std)\n",
    "\n",
    "# === Portfolio Returns ===\n",
    "\n",
    "# Calculate returns using the optimized weights\n",
    "returns_risk_parity = assets.dot(weights_risk_parity)\n",
    "returns_min_variance = assets.dot(weights_min_variance)\n",
    "returns_max_diversification = assets.dot(weights_max_diversification)\n",
    "\n",
    "# Combine portfolio returns into a DataFrame and include VASIX benchmark returns\n",
    "performance_df = pd.DataFrame({\n",
    "    'Risk Parity': returns_risk_parity,\n",
    "    'Minimum Variance': returns_min_variance,\n",
    "    'Maximum Diversification': returns_max_diversification,\n",
    "    'VASIX (Benchmark)': data['Vanguard LifeStrategy Income Fund (VASIX)']\n",
    "})\n",
    "\n",
    "# === Build Tables for Weights and Risk Contributions ===\n",
    "\n",
    "def build_weight_table():\n",
    "    \"\"\"Create a table for weights only.\"\"\"\n",
    "    table = pd.DataFrame({\n",
    "        'Asset': asset_columns,\n",
    "        'Risk Parity': weights_risk_parity * 100,\n",
    "        'Min Variance': weights_min_variance * 100,\n",
    "        'Max Diversification': weights_max_diversification * 100\n",
    "    }).round(2)\n",
    "    return table\n",
    "\n",
    "def build_risk_contrib_table():\n",
    "    \"\"\"Create a table for risk contributions only.\"\"\"\n",
    "    risk_contrib_rp = risk_contribution(weights_risk_parity, cov_matrix) / portfolio_volatility(weights_risk_parity, cov_matrix) * 100\n",
    "    risk_contrib_mv = risk_contribution(weights_min_variance, cov_matrix) / portfolio_volatility(weights_min_variance, cov_matrix) * 100\n",
    "    risk_contrib_md = risk_contribution(weights_max_diversification, cov_matrix) / portfolio_volatility(weights_max_diversification, cov_matrix) * 100\n",
    "    \n",
    "    table = pd.DataFrame({\n",
    "        'Asset': asset_columns,\n",
    "        'Risk Parity': risk_contrib_rp,\n",
    "        'Min Variance': risk_contrib_mv,\n",
    "        'Max Diversification': risk_contrib_md\n",
    "    }).round(2)\n",
    "    return table\n",
    "\n",
    "# === Annual Returns Table ===\n",
    "\n",
    "def build_annual_returns_table():\n",
    "    \"\"\"Create a table for annual returns.\"\"\"\n",
    "    annual_returns_rp = calculate_annual_returns(performance_df, 'Risk Parity')\n",
    "    annual_returns_mv = calculate_annual_returns(performance_df, 'Minimum Variance')\n",
    "    annual_returns_md = calculate_annual_returns(performance_df, 'Maximum Diversification')\n",
    "    annual_returns_vasix = calculate_annual_returns(performance_df, 'VASIX (Benchmark)')\n",
    "    \n",
    "    table = pd.DataFrame({\n",
    "        'Risk Parity (%)': annual_returns_rp,\n",
    "        'Minimum Variance (%)': annual_returns_mv,\n",
    "        'Maximum Diversification (%)': annual_returns_md,\n",
    "        'VASIX (Benchmark) (%)': annual_returns_vasix\n",
    "    })\n",
    "    return table\n",
    "\n",
    "# === Performance Metrics Table ===\n",
    "\n",
    "def build_performance_metrics(df, name):\n",
    "    \"\"\"Calculate CAGR, Standard Deviation, and Maximum Drawdown.\"\"\"\n",
    "    cagr = calculate_cagr(df, name)\n",
    "    std_dev = df[name].std() * np.sqrt(12) * 100  # Annualized standard deviation\n",
    "    mdd = calculate_max_drawdown(df, name)\n",
    "    \n",
    "    return pd.Series({'CAGR (%)': cagr, 'Standard Deviation (%)': std_dev, 'Maximum Drawdown (%)': mdd}).round(2)\n",
    "\n",
    "def build_performance_metrics_table():\n",
    "    \"\"\"Create a table for performance metrics.\"\"\"\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Risk Parity': build_performance_metrics(performance_df, 'Risk Parity'),\n",
    "        'Minimum Variance': build_performance_metrics(performance_df, 'Minimum Variance'),\n",
    "        'Maximum Diversification': build_performance_metrics(performance_df, 'Maximum Diversification'),\n",
    "        'VASIX (Benchmark)': build_performance_metrics(performance_df, 'VASIX (Benchmark)')\n",
    "    })\n",
    "    return performance_metrics\n",
    "\n",
    "# === Generate Tables ===\n",
    "\n",
    "# Generate the tables\n",
    "weights_table = build_weight_table()\n",
    "risk_contrib_table = build_risk_contrib_table()\n",
    "annual_returns_table = build_annual_returns_table()\n",
    "performance_metrics_table = build_performance_metrics_table()\n",
    "\n",
    "# Display the tables\n",
    "print(\"Portfolio Weights Table (%):\")\n",
    "print(weights_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nRisk Contribution Table (%):\")\n",
    "print(risk_contrib_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nAnnual Return Table (%):\")\n",
    "print(annual_returns_table.to_string())\n",
    "\n",
    "print(\"\\nPerformance Metrics Table:\")\n",
    "print(performance_metrics_table.round(2).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099e914-ff55-4e9f-8c8f-bf0a92e666e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
